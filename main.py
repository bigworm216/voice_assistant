#!/usr/bin/env python3
# ä¸»ç¨‹åºæ¨¡å—ï¼šåè°ƒå„ç»„ä»¶å·¥ä½œæµç¨‹
# å®ç°è¯­éŸ³åŠ©æ‰‹çš„ä¸»å¾ªç¯ï¼ŒåŒ…æ‹¬å”¤é†’è¯ç›‘å¬ã€å¯¹è¯å¤„ç†å’Œèµ„æºæ¸…ç†
import asyncio
from pathlib import Path
from config import CONFIG
from utils import logger
import sounddevice as sd
import numpy as np
from stt import load_model, transcribe  # â† æ–°å¢
from llm import ask
from tts import speak
from utils import MemoryManager, AudioBufferCleaner, WhisperModelCleaner
from wakeword import WakeWordDetector
import os
import resource
import sounddevice as sd
from faster_whisper import WhisperModel
from .audio import AudioManager
from .wakeword import WakeWordDetector
from .stt import WhisperOptimizer
from .utils import (
    MemoryManager, AudioBufferCleaner, WhisperModelCleaner, TTSCleaner,
    structured_logger, cache_manager, state
)

class VoiceAssistant:
    _http_session = None

    def __init__(self):
        """åˆå§‹åŒ–è¯­éŸ³åŠ©æ‰‹"""
        load_model()  # â† æ”¹ä¸ºç›´æ¥è°ƒç”¨ stt.py å‡½æ•°

    async def init_async(self):
        """å¼‚æ­¥åˆå§‹åŒ–HTTPä¼šè¯"""
        if VoiceAssistant._http_session is None:
            import aiohttp
            VoiceAssistant._http_session = aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=10),
                connector=aiohttp.TCPConnector(limit_per_host=3)
            )
            logger.info("ğŸŒ HTTPä¼šè¯å·²åˆ›å»º")

    def record_audio(self) -> np.ndarray:
        """å½•åˆ¶éŸ³é¢‘"""
        logger.info(f"ğŸ¤ å½•éŸ³ä¸­ï¼ˆ{CONFIG['duration']}ç§’ï¼‰...")
        audio = sd.rec(
            int(CONFIG["sample_rate"] * CONFIG["duration"]),
            samplerate=CONFIG["sample_rate"],
            channels=1,
            dtype=np.int16
        )
        sd.wait()
        return audio

    async def run(self):
        """ä¸»è¿è¡Œå¾ªç¯"""
        try:
            audio = self.record_audio()
            if audio is None:
                return
            query = transcribe(audio)  # â† ç›´æ¥è°ƒç”¨ stt.py å‡½æ•°
            if not query:
                logger.warning("âš ï¸ æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¾“å…¥")
                return
            logger.info(f"ğŸ‘‚ è¯†åˆ«ç»“æœ: {query}")
            reply = await ask(query)
            logger.info(f"ğŸ¤– ç™¾åº¦å›å¤: {reply}")
            raw = await speak(reply)
            from audio import play
            play(raw)
        except Exception as e:
            logger.error(f"ğŸ’¥ ç³»ç»Ÿé”™è¯¯: {e}")
        finally:
            if VoiceAssistant._http_session:
                import aiohttp
                await VoiceAssistant._http_session.close()
                logger.info("ğŸŒ HTTPä¼šè¯å·²å…³é—­")


# ä¿®å¤å¯¼å…¥é”™è¯¯å’Œé‡å¤å¯¼å…¥
import asyncio
import os
from pathlib import Path
import numpy as np
import sounddevice as sd
from faster_whisper import WhisperModel
from config import CONFIG
from audio import AudioManager
from wakeword import WakeWordDetector
from stt import WhisperOptimizer
from tts import text_to_speech
from llm import call_baidu_api_optimized, get_local_fallback_response
from utils import (
    logger, structured_logger, state, cache_manager,
    MemoryManager, AudioBufferCleaner, WhisperModelCleaner, TTSCleaner
)

# ç§»é™¤æœªä½¿ç”¨çš„VoiceAssistantç±»å®šä¹‰

async def main():
    ""ä¸»å¾ªç¯""
    logger.info("ğŸš€ è¯­éŸ³åŠ©æ‰‹å¯åŠ¨")
    logger.info(f"ğŸ“‹ å”¤é†’è¯: {', '.join(CONFIG['wake_words'])}")
    
    # åˆå§‹åŒ–ç»„ä»¶
    model = initialize_models()
    device_id = initialize_audio()
    audio_manager = AudioManager(device_id, CONFIG["sample_rate"], CONFIG["audio_chunk_size"])
    wake_detector = WakeWordDetector()
    whisper_optimizer = WhisperOptimizer(model)
    memory_manager = MemoryManager()
    
    # åˆå§‹åŒ–æ¸…ç†å™¨
    audio_cleaner = AudioBufferCleaner(audio_manager)
    whisper_cleaner = WhisperModelCleaner(whisper_optimizer)
    tts_cleaner = TTSCleaner()
    
    # æ³¨å†Œæ¸…ç†å›è°ƒ
    memory_manager.add_cleanup_callback(audio_cleaner.cleanup)
    memory_manager.add_cleanup_callback(whisper_cleaner.cleanup)
    memory_manager.add_cleanup_callback(tts_cleaner.cleanup)
    memory_manager.add_cleanup_callback(cache_manager.clear_expired)
    
    try:
        # æ·»åŠ ç¼ºå¤±çš„HTTPä¼šè¯åˆå§‹åŒ–
        await initialize_http_session()
        
        with audio_session(audio_manager):
            while True:
                # ç›‘å¬å”¤é†’è¯
                logger.info("ğŸ‘‚ ç›‘å¬å”¤é†’è¯...")
                audio = audio_manager.record_for_duration(CONFIG["listen_duration"])
                
                if audio is None:
                    continue
                
                # æ£€æµ‹å”¤é†’è¯
                is_wake_word, score = wake_detector.detect(audio)
                if not is_wake_word:
                    logger.debug(f"æœªæ£€æµ‹åˆ°å”¤é†’è¯ (ç½®ä¿¡åº¦: {score:.2f})")
                    continue
                
                logger.info(f"ğŸ¯ æ£€æµ‹åˆ°å”¤é†’è¯ (ç½®ä¿¡åº¦: {score:.2f})")
                
                # å¯¹è¯é˜¶æ®µ
                logger.info("ğŸ’¬ è¿›å…¥å¯¹è¯æ¨¡å¼...")
                audio = audio_manager.record_until_silence(
                    CONFIG["silence_duration"],
                    CONFIG["max_conversation_time"]
                )
                
                if audio is None:
                    logger.warning("âš ï¸ å¯¹è¯å½•éŸ³å¤±è´¥")
                    continue
                
                query = whisper_optimizer.transcribe_conversation_optimized(audio)
                if not query:
                    logger.warning("âš ï¸ æœªè¯†åˆ«åˆ°è¯­éŸ³")
                    continue
                
                logger.info(f"ğŸ—£ï¸ è¯†åˆ«ç»“æœ: {query}")
                
                # æœ¬åœ°å¤‡ç”¨å“åº”æ£€æŸ¥
                response = get_local_fallback_response(query)
                if not response:
                    # è°ƒç”¨LLM
                    response = await call_baidu_api_optimized(query)
                
                if response:
                    logger.info(f"ğŸ¤– å›å¤: {response[:50]}...")
                    await text_to_speech(response)
                
                # æ€§èƒ½ç»Ÿè®¡
                whisper_optimizer.print_performance_stats()
                
                # å®šæœŸæ¸…ç†
                if state.conversation_count % CONFIG["cleanup_interval"] == 0:
                    memory_manager.force_cleanup("å®šæœŸæ¸…ç†")
                
                state.conversation_count += 1
                await asyncio.sleep(0.5)
                
    except KeyboardInterrupt:
        logger.info("ğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
    except Exception as e:
        logger.error(f"ä¸»å¾ªç¯é”™è¯¯: {e}", exc_info=True)
    finally:
        memory_manager.force_cleanup("ç¨‹åºé€€å‡ºæ¸…ç†")
        await close_http_session()
        logger.info("ğŸ‘‹ è¯­éŸ³åŠ©æ‰‹å·²é€€å‡º")

    logger.info(f"ğŸ‘‚ è¯†åˆ«ç»“æœ: {query}")
    reply = await ask(query)
    logger.info(f"ğŸ¤– ç™¾åº¦å›å¤: {reply}")
    raw = await speak(reply)
    from audio import play
    play(raw)

    await VoiceAssistant._http_session.close()

    logger.info("ğŸŒ HTTPä¼šè¯å·²å…³é—­")

# æ·»åŠ æ¨¡å‹å’ŒéŸ³é¢‘åˆå§‹åŒ–å‡½æ•°
def initialize_models():
    ""é’ˆå¯¹ç¡¬ä»¶ä¼˜åŒ–çš„æ¨¡å‹åˆå§‹åŒ–""
    structured_logger.log_operation("Whisperæ¨¡å‹åˆå§‹åŒ–", "å¼€å§‹")
    
    try:
        # CPUä¼˜åŒ–è®¾ç½®
        os.environ['OMP_NUM_THREADS'] = '2'
        os.environ['MKL_NUM_THREADS'] = '2'
        
        model = WhisperModel(
            model_size_or_path=CONFIG["model_path"],
            device="cpu",
            compute_type=CONFIG["compute_type"],
            local_files_only=True,
            cpu_threads=2,
            num_workers=1
        )
        structured_logger.log_success("Whisperæ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        return model
    except Exception as e:
        structured_logger.log_error("Whisperæ¨¡å‹åˆå§‹åŒ–å¤±è´¥", str(e))
        raise


def initialize_audio():
    ""éŸ³é¢‘è®¾å¤‡åˆå§‹åŒ–""
    structured_logger.log_operation("éŸ³é¢‘è®¾å¤‡åˆå§‹åŒ–", "å¼€å§‹")
    
    try:
        # é‡ç½®éŸ³é¢‘å­ç³»ç»Ÿ
        sd._terminate()
        sd._initialize()
        
        devices = sd.query_devices()
        usb_devices = [i for i, device in enumerate(devices) if device['max_input_channels'] > 0 and 'USB' in str(device).upper()]
        
        if usb_devices:
            device_id = usb_devices[0]
            audio_logger.info(f"ä½¿ç”¨USBéŸ³é¢‘è®¾å¤‡: {device_id}")
        else:
            device_id = sd.default.device[0]
            audio_logger.info(f"ä½¿ç”¨é»˜è®¤éŸ³é¢‘è®¾å¤‡: {device_id}")
        
        # æµ‹è¯•éŸ³é¢‘è®¾å¤‡
        with sd.InputStream(samplerate=CONFIG["sample_rate"], channels=1, device=device_id):
            pass
        
        structured_logger.log_success("éŸ³é¢‘è®¾å¤‡åˆå§‹åŒ–å®Œæˆ")
        return device_id
    except Exception as e:
        structured_logger.log_error("éŸ³é¢‘è®¾å¤‡åˆå§‹åŒ–å¤±è´¥", str(e))
        raise

if __name__ == "__main__":
    import os, sys
    if os.geteuid() == 0:
        logger.warning("âš ï¸ ä¸å»ºè®®ä»¥rootç”¨æˆ·è¿è¡Œ")
    if sys.platform == 'win32':
        import asyncio
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    asyncio.run(main())
